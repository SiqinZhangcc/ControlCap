model:
  arch: reem_vicuna

  # pretrained weights
  pretrained: "ckpts/blip2/blip2_pretrained.pth"
  finetune_llm: False

  # contextual visual embedding
  vit_model: "eva_clip_g"
  img_size: 224
  drop_path_rate: 0
  use_grad_checkpoint: False
  vit_precision: "fp16"
  freeze_vit: True

  # tagging head
  tag_bert_config: "reem/models/tag_heads/tag_bert_config.json"
  tag_list: "reem/commom/tag_parser/ram_tag_list.txt"

  # align network
  num_query_token: 32

  # large language model
  llm_model: "ckpts/vicuna-v1.5-7b"

  # inference
  apply_lemmatizer: False
  max_txt_len: 128
  do_sample: False
  num_beams: 5
  max_length: 20 # 10
  min_length: 1
  top_p: 0.9
  repetition_penalty: 1.5
  length_penalty: 0
  num_return_sequences: 1
  temperature: 1
  split_size: 20

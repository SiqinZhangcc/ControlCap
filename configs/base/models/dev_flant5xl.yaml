model:
  arch: dev_t5

  # pretrained weights
  pretrained: "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xl.pth"
  finetune_llm: False

  # contextual visual embedding
  vit_model: "eva_clip_g"
  img_size: 224
  drop_path_rate: 0
  use_grad_checkpoint: False
  vit_precision: "fp16"
  freeze_vit: True

  # tagging head
  tag_bert_config: "controlcap/models/tag_heads/tag_bert_config.json"
  tag_list: "controlcap/common/tagging/ram_tag_list.txt"

  # align network
  num_query_token: 32

  # large language model
  t5_model: "google/flan-t5-xl"

#  # inference
  first_word_control: False
  apply_lemmatizer: False
  max_txt_len: 32
#  do_sample: False
#  num_beams: 5
#  max_length: 20 # 10
#  min_length: 1
#  top_p: 0.9
#  repetition_penalty: 1.5
#  length_penalty: 0
#  num_return_sequences: 1
#  temperature: 1
#  split_size: 20